{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19571e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import faiss\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# Connect to Elasticsearch\n",
    "es = Elasticsearch(hosts=[\"http://localhost:9200\"])\n",
    "\n",
    "# Load BERT Model for Embedding\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Generate Embeddings for FAISS\n",
    "corpus = [\"Elasticsearch is a search engine.\", \"FAISS is used for semantic search.\"]\n",
    "corpus_embeddings = model.encode(corpus)\n",
    "\n",
    "# Build FAISS Index\n",
    "dimension = corpus_embeddings.shape[1]\n",
    "faiss_index = faiss.IndexFlatL2(dimension)\n",
    "faiss_index.add(np.array(corpus_embeddings))\n",
    "\n",
    "# Query Input\n",
    "query = \"What is semantic search?\"\n",
    "query_embedding = model.encode([query])\n",
    "\n",
    "# FAISS Search\n",
    "distances, indices = faiss_index.search(np.array(query_embedding), k=2)\n",
    "faiss_results = [corpus[i] for i in indices[0]]\n",
    "\n",
    "# Elasticsearch Search\n",
    "es_query = {\"query\": {\"match\": {\"content\": query}}}\n",
    "es_response = es.search(index=\"knowledge_base\", body=es_query)\n",
    "es_results = [hit[\"_source\"][\"content\"] for hit in es_response[\"hits\"][\"hits\"]]\n",
    "\n",
    "# Combine Results\n",
    "combined_results = faiss_results + es_results\n",
    "\n",
    "# Generate Answer with T5\n",
    "generator = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "context = \" \".join(combined_results)\n",
    "input_text = f\"question: {query} context: {context}\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "output = generator.generate(input_ids, max_length=50)\n",
    "print(\"Generated Answer:\", tokenizer.decode(output[0], skip_special_tokens=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
